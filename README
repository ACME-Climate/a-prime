Python based scripts to generate ACME Coupled Priority Metrics 


#Meaning of acronyms/words used in variable names below:
#       test:           Test case
#       ref:            Reference case
#       ts:             Time series; e.g. test_begin_yr_ts, here ts refers to time series
#       climo:          Climatology
#       begin_yr:       Model year to start analysis 
#       end_yr:         Model year to end analysis
#       condense:       Create a new file for each variable with time series data for that variable.
#                       This is used to create climatology (if not pre-computed) and in generating time series plots
#       archive_dir:    Location of model generated output directory
#       scratch_dir:    Location of directory where the user wants to store files generated by the diagnostics.
#                       This includes climos, remapped climos, condensed files and data files used for plotting. 


To use on EDISON OR RHEA: 

I. System Setup Requirements:
 
		None

		The anaconda-2.7-climate env built for acme includes all the required packages
		The driver script loads anaconda-2.7-climate


II. Choose driver script: On EDISON, the driver script is run_EDISON.csh, on RHEA it is run_RHEA.csh


III. Set case specific variables in driver script (run_EDISON.csh or run_RHEA.csh):

	1. Where marked, set the test case and reference case specific variables in run_EDISON.csh:

		TEST CASE SPECIFIC VARIABLES

		test_casename                    name of model run case  
		test_native_res                  resolution of the case (e.g. ne30, ne120)
		test_archive_dir                 location of case output history files  
		test_short_term_archive          Is the short term archiving directory structure being used? 1 = True, 0 = False
                                    		 e.g. ...$casename/atm/hist, ...$casename/ocn/hist
		test_begin_yr_climo              Start year for computing climatology diagnostics
		test_end_yr_climo                End year for computing climatology diagnostics
		test_begin_yr_ts                 Start year for computing time series diagnostics
		test_end_yr_ts                   End year for computing time series diagnostics
		

		REFERENCE CASE VARIABLES (SIMILAR TO TEST_CASE VARIABLES)
		CURRENTLY USED ONLY FOR ATM, OCN DIAGS COMPARE AGST. OBS AND A B1850 ACMEv0 RUN)

		ref_case                         name of reference model run case 
						 or set to 'obs' for comparison agst. observations
		ref_archive_dir                  location of reference case history files or observational data

		The following are ignored/not needed if ref_case is obs
		ref_native_res                   resolution of reference case  (e.g. ne30, ne120)
		ref_short_term_archive           Is the short term archiving directory structure being used? 1 = True, 0 = False
                                                 e.g. ...$casename/atm/hist, ...$casename/ocn/hist
		ref_begin_yr_climo               Start year for computing climatology diagnostics
		ref_end_yr_climo                 End year for computing climatology diagnostics
		ref_begin_yr_ts                  Start year for computing time series diagnostics
		ref_end_yr_ts                    End year for computing time series diagnostics


	   The driver script calls the atm and ocn diags scripts.


	2. Switches (True(1)/False(0)) to condense variables, compute climos, remap climos and condensed time series file
	   If no pre-processing is done (climatology, remapping), all the switches below should be 1

		test_compute_climo               Compute climatology for variables for test case
						 Set to 1 if climatologies have not been computed previously
						 If set to 0, the scripts would look for climatology files
		test_remap_climo                 Remap climatology files to observational grids
						 All climatology plots require remapped files to observational grids,
						 even for model to model comparisons
						 Set to 1, if remapping has not been performed earlier
						 e.g. If diagnostics are run for the first time on the case set to 1
						 If set to 0, the scripts would look for climatology files
		test_condense_field_climo        Condense each variable into a separate file with time series data,
						 for climatology variables
						 Ignored if test_compute_climo = 0
		 				 If test_condense_field_climo = 1 and test_compute_climo = 0,
		 				 the script will look for a condensed file 
		test_condense_field_ts           Condense each variable into a separate file with time series data,
                                                 for all time series variables
		test_remap_ts                    Remap time series files to observational grids
						 Set to 1, if remapping has not been performed earlier 
                                                 e.g. If diagnostics are run for the first time on the case set to 1


	   Similarly for the reference case (ignored if ref_case = obs)

		ref_condense_field_climo         
		ref_condense_field_ts            
		ref_compute_climo                
		ref_remap_climo                  
		ref_remap_ts                     

	3. Switch on the diagnostics required (1 = True, 0 = False), e.g.
		generate_atm_diags
		genearate_ocnice_diags

	   For ocn/ice diagnostics select specific diagnostics needed
		generate_ohc_trends
		generate_seaice_climo
		...

	4. Switch on html index.html generation:
		generate_html

	3. Point to the right observational data, mapping files and output locations if the defaults are not optimal:

		ATM:

		data_dir: 	            location of the atm  observational data files

		GPCP_regrid_wgt_file:       location of mapping file for interpolation from native_res to GPCP grid.
		CERES_EBAF_regrid_wgt_file: location of mapping file for interpolation from native_res to CERES_EBAF grid
		ERS_regrid_wgt_file: 	    location of mapping file for interpolation from native_res to ERS grid.

		OCN:
		mpas_meshfile              location of mpas mesh file
		mpas_remapfile             location of maps remap file
		model_tocompare_remapfile  location of remap file of reference model
		mpas_climodir              location to save climos (currently the scratch_dir)


		obs_seaicedir              location of observational datasets of seaice
		obs_iceareaNH              location of NH ice area data
		obs_iceareaSH              location of SH ice area data
		obs_icevolNH               location of NH ice volume data               
		obs_icevolSH               location of SH ice volume data

		casename_model_tocompare   reference model casename to compare against
		ocndir_model_tocompare     location reference model ocn data 
		seaicedir_model_tocompare  location of reference model ice data


		scratch_dir:                location to put intermediate files and data files used for making final plots.
		plots_dir: 		    location where the plot images are saved
		log_dir:                    location where the log files are saved
		www_dir:		    location of a public www folder if available for posting plots

	5. Execute driver script (e.g. "csh run_EDISON.csh") to run the diagnostics and create an html file.

	   or, submit a batch job for longer runs:

	   On EDISON:
	  	sbatch run_EDISON.sl

		Check job status using sqs -u $USERNAME

	   On RHEA:
		qsub run_RHEA.pbs

		Check job status using qstat -u $USERNAME


NOTES ABOUT SOFTWARE DESIGN:

1. The script is flexible and extensible, meaning it is easy to add 
   more variables and observational datasets to the current set.

2. Climatology diagnostics variables and their details are listed in the files:
	 var_list_model_vs_model_climo.csh	For model vs. model comparisons
	 var_list_model_vs_obs_climo.csh	For model vs. obs comparisons
   Time Series diagnostics variables and their details are listed in the files:
	 var_list_model_vs_model_time_series.csh	For model vs. model comparisons
	 var_list_model_vs_obs_time_series.csh		For model vs. model comparisons
	
   These lists can be easily extended to include other variables as needed,
   simply by adding their details in the format used in the files. 

3. Multiple cases can be compared against a ref_case simultaneously, each comparison generating its own webpage.
   In the works!

4. The scripts generate separate log files for each step, making it easy to debug

5. Several intermediary data files are written at various steps, making it easy to debugs

6. The data files used for making the plots are also saved.


Things to do:

1. Accelerate code by harnessing parallelism further by submitting more jobs in the background
2. Remove redundancies
3. Generate easy-to-read log files for the ocn
4. Generate mapping files for T85 and T341 (high res project) runs.




 
